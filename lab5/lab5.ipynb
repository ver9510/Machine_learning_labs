{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лабораторная работа №5**  \n",
    "**Метрики качества классификации**  \n",
    "Выполнила: Иппо Вера, гр. P4117  \n",
    "**Цель работы:** рассмотреть различные метрики качества классификации, входящих\n",
    "в состав библиотеки scikit-learn.  \n",
    "**Исходные данные**   \n",
    "Датасет: https://archive.ics.uci.edu/ml/datasets/Letter+Recognition  \n",
    "Предметная область: буквы латинского алфавита  \n",
    "Задача: определить, какой из букв латинского алфавита соответствует набор характеристик ее написания.  \n",
    "Количество записей: 20000  \n",
    "Количество атрибутов: 16  \n",
    "**Атрибуты:**  \n",
    "lettr capital letter (26 values from A to Z)  \n",
    "x-box horizontal position of box (integer)  \n",
    "y-box vertical position of box (integer)  \n",
    "width width of box (integer)  \n",
    "high height of box (integer)  \n",
    "onpix total # on pixels (integer)  \n",
    "x-bar mean x of on pixels in box (integer)  \n",
    "y-bar mean y of on pixels in box (integer)  \n",
    "x2bar mean x variance (integer)  \n",
    "y2bar mean y variance (integer)  \n",
    "xybar mean x y correlation (integer)  \n",
    "x2ybr mean of x x y (integer)  \n",
    "xy2br mean of x y y (integer)  \n",
    "x-ege mean edge count left to right (integer)  \n",
    "xegvy correlation of x-ege with y (integer)  \n",
    "y-ege mean edge count bottom to top (integer)  \n",
    "yegvx correlation of y-ege with x (integer)  \n",
    "\n",
    "Расчет характеристик будет проводиться для метода опорных векторов и Random Forest алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность классификации (Classification Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузка датасета\n",
    "def load_dataset(filename):\n",
    "\tcsv_dataset = pandas.read_csv(filename, header=None).values\n",
    "\tdataset=csv_dataset\n",
    "\treturn dataset\n",
    "\t\n",
    "#разбиение на обучающую и тестовую выборки\n",
    "dataset=load_dataset(\"letter-recognition.csv\")\n",
    "letter_attr = dataset[:,1:] # список атрибутов (признаков) для каждой буквы\n",
    "letter_class = dataset[:,0] # классы букв\n",
    "data_train, data_test, class_train, class_test = train_test_split(letter_attr, letter_class, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_classification_accuracy(method_name, method):\n",
    "    scoring = 'accuracy'\n",
    "    accuracy = cross_val_score(method, letter_attr, letter_class, cv=5,scoring=scoring)\n",
    "    print(\"Accuracy for \",method_name,\": %.3f (%.3f)\" % (accuracy.mean(),accuracy.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100).fit(data_train, class_train)\n",
    "svc = svm.SVC(kernel='rbf', gamma=0.04, C=10,probability=True).fit(data_train, class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  Random Forest : 0.966 (0.005)\n",
      "Accuracy for  SVC : 0.981 (0.006)\n"
     ]
    }
   ],
   "source": [
    "calc_classification_accuracy(\"Random Forest\",forest)\n",
    "calc_classification_accuracy(\"SVC\",svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логарифм функции правдоподобия (Logarithmic Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logarithmic_loss(method_name, method):\n",
    "    scoring = 'neg_log_loss'\n",
    "    methodLoss = cross_val_score(method, letter_attr, letter_class, cv=5, scoring=scoring)\n",
    "    print(\"Logarithmic loss for \",method_name,\": %.3f (%.3f)\" % (methodLoss.mean(), methodLoss.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_logarithmic_loss(\"Random Forest\",forest)\n",
    "calc_logarithmic_loss(\"SVC\",svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logarithmic loss for  Random Forest : -0.276 (0.009)  \n",
    "Logarithmic loss for  SVC : -0.088 (0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Область под кривой ошибок (Area Under ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc(method, method_name):\n",
    "    new_dataset=numpy.array([element for element in dataset if (element[0] in ['O','I'])])\n",
    "    x_attr=new_dataset[:, 1:]\n",
    "    y_class=new_dataset[:, 0]\n",
    "    bin_y= label_binarize(list(y_class), classes=['A', 'O'])\n",
    "    y_class=numpy.array([element[0] for element in bin_y ])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_attr, y_class, test_size=0.3)\n",
    "    \n",
    "    classifier = OneVsRestClassifier(method)\n",
    "    method_result = classifier.fit(x_train, y_train)\n",
    "    scoring = 'roc_auc'\n",
    "    auc = cross_val_score(method_result, x_attr, y_class, cv=5, scoring=scoring)\n",
    "    print(\"auc \",method_name,\": %.3f (%.3f)\" % (auc.mean(), auc.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_forest = RandomForestClassifier(n_estimators=100)\n",
    "new_svc = svm.SVC(kernel='rbf', gamma=0.04, C=10,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc  Random forest : 1.000 (0.000)\n",
      "auc  SVC : 1.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "calc_auc(new_forest,\"Random forest\")\n",
    "calc_auc(new_svc,\"SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица неточностей (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion_matrix(method_name, method):\n",
    "    predict = method.predict(data_test)\n",
    "    matrix = confusion_matrix(class_test, predict)\n",
    "    print(\"Confusion matrix \",method_name,\":\\n\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix  Random Forest :\n",
      " [[242   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0 229   0   1   1   0   0   3   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   1   4   0   0   0   0]\n",
      " [  0   0 224   0   4   1   2   0   0   0   0   0   0   0   1   0   3   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  1   1   0 246   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0 192   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   1]\n",
      " [  0   3   0   1   1 218   0   0   0   0   0   0   1   1   0   6   0   0\n",
      "    1   7   0   0   1   0   1   0]\n",
      " [  0   1   3   4   2   0 225   0   0   0   0   0   0   0   1   0   3   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   1   0   2   3 210   0   0   7   0   0   0   0   0   1   4\n",
      "    0   0   0   0   0   1   0   0]\n",
      " [  0   2   0   0   0   1   0   0 223   9   0   0   0   0   0   4   0   0\n",
      "    1   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   4 198   0   2   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   0   0   5   0   0 199   0   0   0   0   0   0   9\n",
      "    0   0   2   0   0   3   0   0]\n",
      " [  0   0   0   0   3   0   0   0   0   0   1 235   0   0   0   0   0   1\n",
      "    2   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0 241   0   0   0   0   0\n",
      "    0   0   0   0   2   0   0   0]\n",
      " [  1   0   0   1   0   0   0   3   0   0   0   0   2 231   2   0   0   2\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  0   1   1   1   0   0   0   0   0   0   0   0   0   0 223   1   2   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   1   5   0   0   0   0   0   0   0   0   0 236   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   1 215   2\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   0   0   0   0   2   0   0   2   0   0   0   0   0   0 190\n",
      "    0   0   0   0   0   1   0   0]\n",
      " [  0   1   0   0   1   1   1   2   0   0   0   0   0   0   0   0   0   1\n",
      "  231   0   0   0   0   0   0   2]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1 214   0   0   0   0   2   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   0   0\n",
      "    0   0 226   0   0   0   0   0]\n",
      " [  0   4   0   0   0   3   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 208   1   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   2   0 219   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   3   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 219   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   5   1   1   0   0 239   0]\n",
      " [  0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0 237]]\n",
      "Confusion matrix  SVC :\n",
      " [[243   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0 233   0   1   0   0   1   3   0   0   1   0   0   0   0   0   0   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0 234   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0 246   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   0 189   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   2]\n",
      " [  0   1   0   2   0 228   1   0   0   1   0   0   0   1   0   4   0   0\n",
      "    0   1   0   1   1   0   0   0]\n",
      " [  0   0   1   1   1   0 236   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   2   0   0   1 217   0   0   4   0   1   0   0   1   0   3\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 231   7   0   0   0   0   0   1   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3 202   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   2   0   0 214   0   0   0   0   0   0   2\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   1   0   0   0 240   0   0   0   0   0   0\n",
      "    1   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 241   0   0   0   0   0\n",
      "    0   0   1   1   1   0   0   0]\n",
      " [  0   0   0   1   0   0   0   2   0   0   0   0   1 235   1   0   0   2\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 227   0   1   0\n",
      "    0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   1   0   0   0 240   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1 217   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   1   0   0   0   1   0   0   1   0   0   0   0   0   0 189\n",
      "    0   0   0   2   0   1   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "  237   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1 218   0   0   0   0   1   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0 227   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0\n",
      "    0   0   0 214   1   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   1   1   0   0   0\n",
      "    0   0   1   0 218   0   0   0]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 221   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0   0   2   0   1 243   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0 238]]\n"
     ]
    }
   ],
   "source": [
    "calc_confusion_matrix(\"Random Forest\",forest)\n",
    "calc_confusion_matrix(\"SVC\",svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчет классификации (Classification Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_report(method_name, method):\n",
    "    predict = method.predict(data_test)\n",
    "    report = classification_report(class_test, predict)\n",
    "    print(\"Classification_report \",method_name,\":\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification_report  Random Forest :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.99      0.99       244\n",
      "          B       0.92      0.95      0.93       240\n",
      "          C       0.98      0.95      0.97       235\n",
      "          D       0.96      0.98      0.97       250\n",
      "          E       0.91      0.98      0.95       195\n",
      "          F       0.94      0.90      0.92       241\n",
      "          G       0.96      0.94      0.95       240\n",
      "          H       0.93      0.91      0.92       230\n",
      "          I       0.98      0.93      0.96       240\n",
      "          J       0.95      0.97      0.96       205\n",
      "          K       0.93      0.90      0.92       220\n",
      "          L       0.99      0.97      0.98       243\n",
      "          M       0.98      0.99      0.98       244\n",
      "          N       0.99      0.95      0.97       243\n",
      "          O       0.97      0.97      0.97       230\n",
      "          P       0.95      0.97      0.96       243\n",
      "          Q       0.96      0.98      0.97       220\n",
      "          R       0.90      0.96      0.93       198\n",
      "          S       0.98      0.96      0.97       240\n",
      "          T       0.95      0.97      0.96       220\n",
      "          U       0.97      0.98      0.98       230\n",
      "          V       0.98      0.95      0.97       218\n",
      "          W       0.98      0.99      0.98       222\n",
      "          X       0.97      0.98      0.98       223\n",
      "          Y       0.98      0.97      0.97       247\n",
      "          Z       0.98      0.99      0.99       239\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6000\n",
      "\n",
      "Classification_report  SVC :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A       1.00      1.00      1.00       244\n",
      "          B       0.96      0.97      0.97       240\n",
      "          C       1.00      1.00      1.00       235\n",
      "          D       0.96      0.98      0.97       250\n",
      "          E       0.96      0.97      0.97       195\n",
      "          F       0.99      0.95      0.97       241\n",
      "          G       0.98      0.98      0.98       240\n",
      "          H       0.95      0.94      0.95       230\n",
      "          I       0.99      0.96      0.97       240\n",
      "          J       0.96      0.99      0.97       205\n",
      "          K       0.97      0.97      0.97       220\n",
      "          L       1.00      0.99      0.99       243\n",
      "          M       0.98      0.99      0.99       244\n",
      "          N       0.99      0.97      0.98       243\n",
      "          O       0.98      0.99      0.98       230\n",
      "          P       0.96      0.99      0.98       243\n",
      "          Q       1.00      0.99      0.99       220\n",
      "          R       0.95      0.95      0.95       198\n",
      "          S       0.99      0.99      0.99       240\n",
      "          T       1.00      0.99      0.99       220\n",
      "          U       0.98      0.99      0.98       230\n",
      "          V       0.96      0.98      0.97       218\n",
      "          W       0.99      0.98      0.98       222\n",
      "          X       0.99      0.99      0.99       223\n",
      "          Y       0.99      0.98      0.99       247\n",
      "          Z       0.99      1.00      0.99       239\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_classification_report(\"Random Forest\",forest)\n",
    "create_classification_report(\"SVC\",svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:**\n",
    "В результате исследования, проведенного в ходе данной лабораторной работы, можно сделать вывод, что SVC алгоритм по всем метрикам лучше, чем алгоритм Random Forest. Оба метода классификации подходят для обработки данного датасета и показывают очень хорошие результаты.Также интересно отметить, что параметры precision и recall алгоритма SVC для  некоторых букв достигает 1, что значит для них не было ни ложных срабатываний, ни ложных пропусков. Возможно это связано с полнотой и большим размером датасета. К сожалению, в связи с большим количеством классов не удалось правильно рассчитать площадь области под кривой ошибок, так как выборка по двум буквам мала и результат не сравним с остальными метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
